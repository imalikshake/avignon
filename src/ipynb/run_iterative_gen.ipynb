{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffab5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import functools\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import PIL\n",
    "import sys\n",
    "import glob\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "sys.path.append('src/py')\n",
    "\n",
    "import ai_utils\n",
    "from image_utils import load_image, show_image, save_image\n",
    "import image_utils as iu\n",
    "import time\n",
    "\n",
    "print(\"TF Version: \", tf.__version__)\n",
    "print(\"TF Hub version: \", hub.__version__)\n",
    "print(\"Eager mode enabled: \", tf.executing_eagerly())\n",
    "print(\"GPU available: \", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c57642",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"/Users/iman/github/avignon/\"    \n",
    "project_dir =  \"projects/graphite/\"\n",
    "input_dir = os.path.join(base_path, project_dir, \"graphite_style\")\n",
    "mask_dir = os.path.join(base_path, project_dir, \"graphite_original\")\n",
    "output_dir = os.path.join(base_path, project_dir, \"output\")\n",
    "styles_dir = os.path.join(base_path, project_dir, \"styles\")\n",
    "temp_dir = os.path.join(base_path, project_dir, \"temp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcf4ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_files = glob.glob(os.path.join(mask_dir, '*'))\n",
    "input_files.sort()\n",
    "\n",
    "content_img_size = (1920, 1080)\n",
    "style_img_size = (1920, 1080)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2015d705",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ebsynth(style, input_file, guide_1, out_dir, uniformity=1,patch_size=5, pyramid_levels=1, search_vote_iters=1, patch_match_iters=1, guide_1_weight=100, guide_2_weight=0.01, guide_2=None):\n",
    "    output_file = os.path.splitext(os.path.basename(input_file))[0]\n",
    "    if guide_2:\n",
    "        command = f\"ebsynth -style {style} \\\n",
    "                -guide {guide_1}  {input_file} -weight {guide_1_weight} \\\n",
    "                -guide {guide_2} {input_file} -weight {guide_2_weight} \\\n",
    "                -output {out_dir}/{output_file}.png \\\n",
    "                -uniformity {uniformity} -patchsize {patch_size} -pyramidlevels {pyramid_levels} -searchvoteiters {search_vote_iters} -patchmatchiters {patch_match_iters} \"\n",
    "    else:\n",
    "        command = f\"ebsynth -style {style} \\\n",
    "                -guide {guide_1}  {input_file} -weight {guide_1_weight} \\\n",
    "                -output {out_dir}/{output_file}.png \\\n",
    "                -uniformity {uniformity} -patchsize {patch_size} -pyramidlevels {pyramid_levels} -searchvoteiters {search_vote_iters} -patchmatchiters {patch_match_iters} \"\n",
    "\n",
    "    subprocess.call(command, shell=True)\n",
    "    return f\"{out_dir}/{output_file}.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1f1192",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_data(csv_path, sep=\"|\"):\n",
    "    data_df = df = pd.read_csv(csv_path, sep=sep,)\n",
    "    ratios = []\n",
    "    for number in data_df[\"numbers\"]:\n",
    "        if '%' in number:\n",
    "            value = number.replace(\"%\", \"\")\n",
    "            ratio = float(value)/100\n",
    "        elif 'jours' in number:\n",
    "            ratio = 1.0\n",
    "        else:\n",
    "            value = int(number)\n",
    "            length = len(str(value))\n",
    "            max_length = int('9' * length)\n",
    "            ratio = value/max_length\n",
    "        ratios.append(ratio)\n",
    "    data_df[\"ratio\"] = ratios\n",
    "    return data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9132c925",
   "metadata": {},
   "outputs": [],
   "source": [
    "collected_csv_path = os.path.join(base_path, \"questions/q_and_a_truth.csv\")\n",
    "collected_df = translate_data(collected_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fea317",
   "metadata": {},
   "outputs": [],
   "source": [
    "collected_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55be8b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "static_csv_path = os.path.join(base_path, \"questions/static_q_and_a.csv\")\n",
    "static_df = translate_data(static_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbda7c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_segments = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289cbd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coords(digit, rows, cols):\n",
    "    position = digit % (rows*cols) \n",
    "    row = position // cols \n",
    "    col = position % cols \n",
    "    return row, col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca65eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def put_text_wrap(image, text, org, font, font_scale, color, thickness, line_spacing, max_width):\n",
    "    words = text.split()  # Split text into individual words\n",
    "    lines = []\n",
    "    current_line = \"\"\n",
    "\n",
    "    for word in words:\n",
    "        # Check if adding the current word exceeds the maximum width\n",
    "        if cv2.getTextSize(current_line + \" \" + word, font, font_scale, thickness)[0][0] <= max_width:\n",
    "            current_line += \" \" + word\n",
    "        else:\n",
    "            lines.append(current_line.strip())\n",
    "            current_line = word\n",
    "\n",
    "    lines.append(current_line.strip())  # Add the last line\n",
    "\n",
    "    # Draw each line of text with appropriate y-coordinates\n",
    "    for i, line in enumerate(lines):\n",
    "        y = org[1] + (i * line_spacing)\n",
    "        cv2.putText(image, line, (org[0], y), font, font_scale, color, thickness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd26196d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_style(input_file, out_dir, segments, static_df, collected_df, grid_rows=6, grid_cols=2, fsize_max=17, fsize_min=7, fstroke_max=12, colour_max=104):\n",
    "    input_image = load_image(input_file)\n",
    "    \n",
    "    height = input_image.shape[0]\n",
    "    width = input_image.shape[1]\n",
    "\n",
    "    blank_image = np.zeros((height, width, 3), np.uint8)\n",
    "    blank_image.fill(0)\n",
    "\n",
    "    cell_width = width // 2\n",
    "    cell_height = height // 6\n",
    "    \n",
    "    joined_df = pd.concat([collected_df, static_df]) \n",
    "\n",
    "\n",
    "    for segment in segments:\n",
    "        seg_joined_df = joined_df[joined_df['question number'] == segment]\n",
    "        i_row, i_col = get_coords(segment, rows=grid_rows, cols=grid_cols)\n",
    "    \n",
    "        x = i_col * cell_width\n",
    "        y = i_row * cell_height - int(cell_height/4)\n",
    "\n",
    "        adj_x = x\n",
    "        adj_y = y + cell_height\n",
    "        \n",
    "        for index, row in seg_joined_df.iterrows():\n",
    "            text = row['question']\n",
    "            ratio = row['ratio']\n",
    "            put_text_wrap(blank_image,text, (adj_x, adj_y),  cv2.FONT_HERSHEY_SIMPLEX, max(12 * ratio, 4), (10, 5, 10), 6, 40, 80)\n",
    "            # cv2.putText(blank_image, text, (adj_x, adj_y), cv2.FONT_HERSHEY_SIMPLEX, fsize_max*1, (10, 10, 10), int(fstroke_max*1))\n",
    "\n",
    "        for index, row in seg_joined_df.iterrows():\n",
    "            text = row['numbers']\n",
    "            ratio = row['ratio']\n",
    "            cv2.putText(blank_image, text, (adj_x, adj_y), cv2.FONT_HERSHEY_SIMPLEX, max(fsize_max*ratio, fsize_min), (255*ratio, colour_max*1, 10), int(fstroke_max*3))\n",
    "            \n",
    "\n",
    "    temp_file_path = os.path.join(out_dir, os.path.basename(input_file))\n",
    "\n",
    "    s_image = iu.overlay(blank_image,input_image)\n",
    "    s_image = iu.edges(s_image)\n",
    "    s_image = cv2.cvtColor(s_image, cv2.COLOR_GRAY2BGR)\n",
    "    s_image = iu.overlay(input_image, s_image, 0.5)\n",
    "    s_image = iu.overlay(blank_image, s_image, 0.1)\n",
    "    s_image = iu.increase_brightness_contrast(s_image, brightness=50, contrast=40)\n",
    "    show_image(s_image, fig_size=(10,5))\n",
    "    save_image(temp_file_path, s_image)\n",
    "    return temp_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929620f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_style(input_file=input_files[4], segments=8, out_dir=temp_dir,static_df=static_df, collected_df=collected_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee727025",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_frames = []\n",
    "frame_rate = 30\n",
    "segments = []\n",
    "base_style_path = input_files[0]\n",
    "for i in range(0,question_segments):\n",
    "    gen_style = False\n",
    "    for j in range(i*frame_rate,(i*frame_rate)+frame_rate):\n",
    "        segments.append(i)\n",
    "        file_idx = j\n",
    "        input_file = input_files[file_idx]\n",
    "        temp_file = os.path.join(temp_dir, os.path.basename(input_files[file_idx]))\n",
    "        mask_file = input_files[file_idx]\n",
    "        out_dir = output_dir\n",
    "\n",
    "\n",
    "        temp_file = get_style(input_file=input_file, out_dir=temp_dir, segments=segments, static_df=static_df, \n",
    "        collected_df=collected_df)\n",
    "\n",
    "        if not gen_style:\n",
    "            style_file = temp_file\n",
    "            gen_style = True\n",
    "\n",
    "        guide_1_weight = 100000\n",
    "        guide_2 = mask_file\n",
    "        guide_2_weight = 1000\n",
    "\n",
    "        start_time = time.time()\n",
    "        output_frames.append(run_ebsynth(style=style_file, guide_2=guide_2, guide_1_weight=guide_1_weight, guide_2_weight=guide_2_weight, input_file=temp_file, guide_1=mask_file, out_dir=out_dir))\n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(\"Elapsed time: {:.2f} seconds\".format(elapsed_time))\n",
    "\n",
    "        show_image(load_image(output_frames[j]), fig_size=(2.5,5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e32282",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f5a1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# width = 1080\n",
    "# height = 1920\n",
    "# temp_files = []\n",
    "# for i in range(0,10):\n",
    "#     blank_image = np.zeros((height, width, 3), np.uint8)\n",
    "#     blank_image.fill(255)\n",
    "#     test_i = load_image(input_files[i])\n",
    "\n",
    "#     grid_rows = 8\n",
    "#     grid_cols = 4\n",
    "\n",
    "#     cell_width = test_i.shape[1] // 4\n",
    "#     cell_height = test_i.shape[0] // 8\n",
    "\n",
    "#     for row in range(grid_rows):\n",
    "#         for col in range(grid_cols):\n",
    "#             # Calculate the position of the cell\n",
    "#             x = col * cell_width\n",
    "#             y = row * cell_height\n",
    "\n",
    "#             # Place the text in the cell\n",
    "#             text = f'(80, 90)'\n",
    "#             cv2.putText(blank_image, text, (x+cell_width//2, y+cell_height//2), cv2.FONT_HERSHEY_SIMPLEX, 10, (255, 0, 0), 5)\n",
    "#     temp_file_path = os.path.join(temp_dir, os.path.basename(input_files[i]))\n",
    "#     # save_image(temp_file_path, test_i)\n",
    "#     temp_files.append(temp_file_path)\n",
    "#     s_image = iu.overlay(blank_image,test_i)\n",
    "#     s_image = iu.edges(s_image)\n",
    "#     s_image = cv2.cvtColor(s_image, cv2.COLOR_GRAY2BGR)\n",
    "#     s_image = iu.overlay(test_i, s_image, 0.5)\n",
    "#     s_image = iu.overlay(blank_image, s_image, 0.5)\n",
    "#     show_image(s_image, fig_size=(10,5))\n",
    "#     # break\n",
    "#     # save_image(temp_file_path, cv2.cvtColor(s_image, cv2.COLOR_BGR2GRAY))\n",
    "#     save_image(temp_file_path, s_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa607a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_frames = []\n",
    "# for i in range(0,10):\n",
    "#     input_file = temp_files[i]\n",
    "#     mask_file = os.path.join(mask_dir, os.path.basename(input_file))\n",
    "#     out_dir = output_dir\n",
    "#     # style = os.path.join(base_path,\"projects/graphite/temp/0010.png\")\n",
    "#     # style = os.path.join(base_path,\"other/text_out2.jpg\")\n",
    "#     style = os.path.join(temp_dir, \"0000.png\")\n",
    "\n",
    "#     # guide_2 = os.path.join(base_path,\"other/text_out.jpg\")\n",
    "#     guide_2 = None\n",
    "#     guide_1_weight = 1000\n",
    "#     guide_2_weight = 1\n",
    "#     start_time = time.time()\n",
    "#     output_frames.append(run_ebsynth(style=style, guide_2=guide_2, guide_1_weight=guide_1_weight, guide_2_weight=guide_2_weight, input_file=input_file, guide_1=mask_file, out_dir=out_dir))\n",
    "#     elapsed_time = time.time() - start_time\n",
    "#     print(\"Elapsed time: {:.2f} seconds\".format(elapsed_time))\n",
    "\n",
    "#     show_image(load_image(output_frames[i]), fig_size=(2.5,5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9b7a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, x in enumerate(output_frames):\n",
    "#     show_image(load_image(output_frames[i]), fig_size=(2.5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1a1a37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
